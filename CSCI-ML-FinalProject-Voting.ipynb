{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f433f019-47ec-4353-ba4a-026f058e2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import plotly as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import plotly.graph_objects as go\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb3566da-f003-4f33-bd98-fcdc3624eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### William Diment - Voter Registration Prediction\n",
    "### In this project, we attempt to identify who in Boulder county could be registered as a democrat or a republican\n",
    "### We do this using the principle of Logistic Regression, as that allows for an easy binary classification of Republican or Democrat\n",
    "### We accomplish this by taking voter data from the Boulder County elections office (https://bouldercounty.gov/elections/maps-and-data/data-access/#Registered-Voter-Data)\n",
    "### We then split that data into two separate CSVs in Excel\n",
    "\n",
    "### We then import the voting data into a pandas dataframe and clean then data\n",
    "### We specify that we want only the Voter ID, the Voter Status, the Birth Year, the Gender, Party Registration, and Precinct Code\n",
    "### Really, for the set of information we have, we really only need the Birth Year, Gender, and Party registration\n",
    "### We then replace the PARTY value with a binary value of 0 for Democratic, and 1 for Republican\n",
    "### We do the same for voter status - 1 is active, 0 is inactive\n",
    "### We then replace Male and Female with 1 and 0 respectively\n",
    "\n",
    "### All of this is done to fit the data into a binary classification form - this is the form a logistic regression learning model takes\n",
    "### We then drop all parties other than democratic or republican - green, constitutionalist, etc\n",
    "\n",
    "def importVotingData():\n",
    "    voterRegistrationSetOne = pd.read_csv('VotingData/VoterDetailsListPart1.csv', sep=',', low_memory=False)\n",
    "    voterRegistrationSetTwo = pd.read_csv('VotingData/VoterDetailsListPart2.csv', sep=',', low_memory=False)\n",
    "    return voterRegistrationSetOne, voterRegistrationSetTwo\n",
    "\n",
    "def cleanVoterRegistrationData(df = None):\n",
    "    df = df[['VOTER_ID', 'VOTER_STATUS',  'BIRTH_YEAR', 'GENDER', 'PRECINCT_CODE', 'PARTY',]]\n",
    "    df.PARTY.replace(['DEM', 'REP'], [0, 1], inplace=True)\n",
    "    df.VOTER_STATUS.replace(['Active', 'Inactive'], [1, 0], inplace=True)\n",
    "    df.GENDER.replace(['Male', 'Female', 'X' , 'Not Disclosed'], [1, 0, 0, 0], inplace=True)\n",
    "    df = df[(df.PARTY == 0) | (df.PARTY == 1)]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "928ff727-67ef-4437-afe8-88d703d40c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here is where we actually execute the cleaning and output the data\n",
    "voterRegistrationSetOne, voterRegistrationSetTwo = importVotingData()\n",
    "voterRegistrationSetOne = cleanVoterRegistrationData(voterRegistrationSetOne)\n",
    "voterRegistrationSetTwo = cleanVoterRegistrationData(voterRegistrationSetTwo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89ac89eb-21f8-4a75-8ef1-869adde2844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We then concatenate the two sets of voter data into a single list\n",
    "voterRegistrationSet = pd.concat([voterRegistrationSetOne, voterRegistrationSetTwo], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e247fd2-857b-4660-86dc-daf9ca6db1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We then make sure that the PARTY column with 0 for Democrat and 1 for Republican is an actual integer, and not a string\n",
    "voterRegistrationSet['PARTY'] = pd.to_numeric(voterRegistrationSet['PARTY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbb78dcb-1459-4da3-bab4-1a372ebb64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I reorganize the columns here just so I can keep them straight in my head\n",
    "### I also made sure to reindex the results so that the row ID is consistent \n",
    "### I didn't need to do this in the end, but it was conceptually important for me to know exactly what I was looking at\n",
    "\n",
    "#reorganizedColumns = ['VOTER_ID', 'VOTER_STATUS','GENDER','BIRTH_YEAR', 'PRECINCT_CODE', 'PARTY', ]\n",
    "reorganizedColumns = ['VOTER_STATUS','GENDER', 'PARTY']\n",
    "voterRegistrationSet = voterRegistrationSet.reindex(columns=reorganizedColumns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca954472-a3af-4497-81fa-2d200682ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        VOTER_STATUS  GENDER  PARTY\n",
      "0                  1       1      0\n",
      "1                  0       0      0\n",
      "2                  1       1      0\n",
      "3                  1       1      0\n",
      "4                  1       1      0\n",
      "...              ...     ...    ...\n",
      "127194             1       1      1\n",
      "127195             0       1      0\n",
      "127196             1       1      0\n",
      "127197             1       0      0\n",
      "127198             1       1      0\n",
      "\n",
      "[127199 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(voterRegistrationSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d8646e2-9216-49a4-a125-64ad205be2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We convert the pandas data set to numpy so I can feed it to the training test split function\n",
    "voterRegistrationSetNumpy = voterRegistrationSet.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2a4ea8c-1750-4684-b08a-461e8bfa32d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predicted voter registration values: 0.7852201257861635\n",
      "\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.208\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.208\n",
      "Method:                 Least Squares   F-statistic:                          1.672e+04\n",
      "Date:                Mon, 09 Dec 2024   Prob (F-statistic):                        0.00\n",
      "Time:                        00:49:23   Log-Likelihood:                         -67919.\n",
      "No. Observations:              127199   AIC:                                  1.358e+05\n",
      "Df Residuals:                  127197   BIC:                                  1.359e+05\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.1577      0.002    100.667      0.000       0.155       0.161\n",
      "x2             0.1274      0.002     56.841      0.000       0.123       0.132\n",
      "==============================================================================\n",
      "Omnibus:                    22257.340   Durbin-Watson:                   1.931\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            36646.412\n",
      "Skew:                           1.314   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.936   Cond. No.                         2.28\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "### Here we use the train_test_split function to split the voter registration into actionable sets of data\n",
    "### I split the train/test size evenly, and make sure to have a high random state for shuffling the data\n",
    "### The Binary variables I match the Logistic Regression model on are: Gender, and Frequent Voting Status (0 for infrequent, 1 for frequent)\n",
    "### Then, I create the Logistic Regression Model, and set its random state as well\n",
    "### It seemed appropriate to choose liblinear as the solver, as overall I do not have that much data - 250k-ish rows\n",
    "### I then fit the model \n",
    "\n",
    "### We then predict the voter registration using the fitted model, and calculate the accuracy score\n",
    "### The accuracy score is decent - (78.5%) but has a slight peculiarity that I will discuss later when displaying graphs\n",
    "### I then extract the actual voter registration numbers and predicted registration numbers using Counter\n",
    "### This gives us a dict of the extracted keys (0, 1) for democratic/republican, and the associated number of actual/predicted voters\n",
    "### I then fit the data using statsmodels so that I can get the associated P values and R Squared values\n",
    "\n",
    "### The R-Squared values being so low does not surprise me - I am training on two sets of features (frequent voter status, gender)\n",
    "### Clearly, not all the variance in data can be explained by those two feature sets\n",
    "### However, we do know from political/social sciences that gender and frequent voting status correspond strongly to political party preference\n",
    "### As such, getting a R-Squared value of 0.208 from this data is not \"horrific\"\n",
    "### We just need more data to explain the variance\n",
    "### I would have thought it would have been a little higher - maybe 0.3, but those are the breaks for this project I suppose\n",
    "### The P values being 0 doesn't surprise. The features are extremely relevant to the model. \n",
    "\n",
    "\n",
    "voterRegistrationSet_train, voterRegistrationSet_test, voterParty_train, voterParty_test = train_test_split(voterRegistrationSetNumpy[:,0:2], voterRegistrationSetNumpy[:,2], test_size=0.5, train_size=0.5, random_state=42)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=10)\n",
    "model.fit(voterRegistrationSet_train, voterParty_train)\n",
    "\n",
    "voterPredict = model.predict(voterRegistrationSet_test)\n",
    "accuracy = accuracy_score(voterParty_test, voterPredict)\n",
    "\n",
    "actualRegistration = dict(Counter(voterParty_test))\n",
    "predictedRegistration = dict(Counter(voterPredict))\n",
    "\n",
    "mod = sm.OLS(voterRegistrationSetNumpy[:,2], voterRegistrationSetNumpy[:,0:2])\n",
    "fit = mod.fit()\n",
    "\n",
    "print(\"Accuracy of predicted voter registration values: {}\\n\".format(accuracy))\n",
    "print(fit.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "678a103a-4df2-452e-ada8-6827e9c3fd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_29.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Here we go. I plot the actual registration, and the predicted registration.\n",
    "### You will notice immediately that the predicted registration does not actually predict any Republican voters!\n",
    "### I tried very long to get it to show some republican voters, but I couldn't seem to get it to fit in the model\n",
    "### Here's the thing though - Colorado is a more-democratic leaning state, and Boulder County even more democratic leaning than that\n",
    "### As such, the majority of people registered in the county affiliate with a party are Democratic party members\n",
    "\n",
    "### From our subset of training data, we get a number of 49.9k Democrats and 13.66k Republicans\n",
    "### As such, roughly 73% of the registered voters here are democratic, and 27% of the voters are Republicans\n",
    "### Thus, the accuracy above being as 78% seems to work with what we are seeing here\n",
    "### I have no clue why the model is overzealous and overfits to democrats specifically in this case\n",
    "### but how we could fix it is by introducing more binary features into the logistic regression\n",
    "### This could take the form of 'yes, no' answers to policy questions and adding them to the feature list\n",
    "### Or, we could take the entirety of the voter registration data, and fit an SVM model to it\n",
    "\n",
    "\n",
    "### Conclusion is below figures\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=['Democrats', 'Republicans'],\n",
    "    y=[actualRegistration[0], actualRegistration[1]],\n",
    "    name='Actual Registration',\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=['Democrats', 'Republicans'],\n",
    "    y=[predictedRegistration[0], 0],\n",
    "    name='Predicted Registration',\n",
    "        )\n",
    "    )\n",
    "fig.update_layout(yaxis=dict(title='Number of Registrations'), xaxis=dict(title='Political Parties'), title=dict(text=\"Actual vs Predicted Registration\"))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58933984-dcd6-4c04-bcc0-b59d53492a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conclusions\n",
    "### In short, identifying and predicting voter registration based on two variables is undesireable, but can achieve passable results \n",
    "### I am not upset with the results, and it is 'accurate', but with more policy questions that could be classified as a 'yes, no' answer \n",
    "### I could have put more data into the model and gotten a better actual result\n",
    "### SVM I believe is the true method that should be used for this, simply because I would be able to make use of ALL the voter registration data\n",
    "### A key piece of data I did not get to use is the Birth Year \n",
    "### Political Science again tells us that the age of a person can correspond with which political party they register with\n",
    "### A very large reach goal could have been to find the average median income of the precinct district of the voter\n",
    "### Income again, is another variable that corresponds strongly to political voting patterns\n",
    "### Either way - this model could be greatly expanded, but the strength of the logistic regression model is here\n",
    "### If I am able to get this far with just two features, I could get much further with even one or two more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab06ec-3a5d-4aaf-92b8-8abb7e926424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c9a15-81e7-44fd-af7f-ce8f0cc10a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556f070-85e0-4569-9b96-f19d16fe3a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
